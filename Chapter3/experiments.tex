In this chapter we present our experimental analysis to understand 
the impact of different choices for encoding our problem. We recall
that \liftcreatehr{}, detailed in Algorithm~\ref{alg:hr}, produces 
at most one solution per \textit{prototype}, i.e., a pair of
car frame and door.
\liftcreatebf{}, \liftcreaters{} and \liftcreatega{} share a common
flow that $(i)$ generates prototypes, $(ii)$ expands design candidates for
each prototype and $(iii)$ validates early designs on the hard constraints
of Section~\ref{sec:model_constraints}. Finally, both \liftcreatecp{}
and \liftcreatesmt{} provide a direct encoding to a MiniZinc or SMT-LIB 
formula which is fed to the corresponding solvers.

\section{Experimental setup}
%
The results are obtained by running the different versions of \liftcreate{}
using the same database to configure RHEs in sixteen different setups. 
In particular, a database of commercial components is considered for
car frames and car doors. In the \liftcreate{} web application, the
database collects all the components described beforehand as well as
some additional support tables that are not considered here. The
component tables have as many columns as the  parameters that are
depicted in Table~\ref{tab:param}, and the tables are built
referencing actual measurements from a few part suppliers. When
\liftcreate{} is required to choose a car frame and a car door, it
queries the database and then initializes the specific procedures with
such data. The results herewith presented consider a database
consisting of 25 car frames, 236 doors and 47 hydraulic cylinders. 
We run the different versions of \liftcreate{} in sixteen different
setups, i.e., configuration scenarios, including both cases in which,
given the available components, feasible  solutions exist, and others
for which there are none. The setups we  consider represent typical
shaft sizes found in residential buildings:  two families of $8$
setups, the former featuring $1300$mm shaft width and  the latter
featuring $1500$mm shaft width; shaft depth varies in both  families
from $800$mm to $1500$mm. Overall, these setups enable a thorough 
evaluation of \liftcreate{} versions considering realistic settings.
All tests run on a PC equipped with an Intel\textregistered  
\hspace{1pt} Core\texttrademark \hspace{1pt} i7-6500U dual core 
CPU @ 2.50GHz, featuring 8GB of RAM and running Ubuntu Linux 
16.04 LTS 64 bit.

Considering the evaluation parameters, we always measure the run time
since the main objective is to deploy an alternative, declarative-based
encoding in order to replace the current heuristic engine. When considering
\liftcreatega{} we also measure some statistical parameters by running
50 samples with a unique seed for each sample. Other measures, e.g.,
size of the explored search space, number of sub-problems generated by the
CSP approaches, might make sense only for specific situations. We also
consider two different sets of experiments: a baseline encoding dealing with
the configuration of the car frame and the door pair only,
and a full encoding dealing also with the selection and sizing of the
hydraulic cylinder as well as the minimization of forces on the car
rails. In particular, in the baseline encoding we consider only the
cost components related to car frame and doors, whereas the full
encoding takes into account all the cost components. \liftcreatega{}
considers only the baseline encoding, as well as \liftcreatecp{}, while
\liftcreatesmt{} is compared on both encodings due to numerical stability
reasons detailed in the next Section. \liftcreatehr{} is tuned to be
compared on both encodings.

When building the cost function, in the single-objective case, considering 
equation (\ref{eq:costfunc_single}), we set the free parameters $\alpha_1$, 
$\alpha_2$ and $\alpha_3$ to $0.3$ and $\alpha_4$ to $0.1$ in order to encode 
different priorities. In the multi-objective encoding, we set all weights to one. 

\section{Experimental results}
%
\paragraph{\liftcreatehr.}
%
\begin{table}[t]
	\caption{\label{table:heuristicResult} Results of computing configurations with 
		heuristic techniques (\liftcreatehr{}) on the baseline encoding: 
		``\textbf{Time}'' is the total runtime in milliseconds, 
		``\textbf{No. of configs.}'' is the total number of feasible configurations 
		found (at most one for each prototype).}
	\setlength{\tabcolsep}{22pt}
	\centering
	\begin{tabular}{l rr}
		\toprule
		{\bf Shaft size} & {\bf Time} & {\bf No. of configs.}\\
		\midrule
		1300 $\times$ 800 & 1271 & 0 \\
		1300 $\times$ 900 & 731 & 54 \\
		1300 $\times$ 1000 & 715 & 51 \\
		1300 $\times$ 1100 & 633 & 89 \\
		1300 $\times$ 1200 & 633 & 168 \\
		1300 $\times$ 1300 & 764 & 397 \\
		1300 $\times$ 1400 & 1062 & 679 \\
		1300 $\times$ 1500 & 966 & 859 \\
		1500 $\times$ 800 & 1213 & 0 \\
		1500 $\times$ 900 & 1250 & 80 \\
		1500 $\times$ 1000 & 1330 & 160 \\
		1500 $\times$ 1100 & 1268 & 198 \\
		1500 $\times$ 1200 & 1544 & 414 \\
		1500 $\times$ 1300 & 1742 & 920 \\
		1500 $\times$ 1400 & 1823 & 1179 \\
		1500 $\times$ 1500 & 1548 & 986 \\
		\bottomrule
	\end{tabular}
\end{table}
%
The results of \liftcreatehr{} on the baseline encoding are reported in
Table~\ref{table:heuristicResult}; as the results show, all the setups 
can be solved in less than 2 CPU seconds. Note that
the heuristic search herewith considered focuses only on the car frame
and doors coupling, so that the results of the full design may appear
inconsistent with~\cite{AiLift2}.
The number of configurations found ranges from $0$ for the
two setups having shaft depth $800$mm, to more than one thousand for deeper 
shafts. Notice that the number of configurations found by \liftcreatehr{} 
may not coincide with the total number of feasible configurations: this is 
because heuristics in \liftcreate{} are geared towards providing arrangements 
that a human designer finds satisfactory and not just feasible ones.
 
To better appreciate the complexity of the configuration task and
the results obtained with \liftcreatehr{}, in~\cite{AiLift4} 
we present also the results obtained with \liftcreatebf{}. In these experiments
we follow the schema depicted in Chapter~\ref{ch:elevator_enc} where both the
prototypes generation and the early designs expansion are performed by a
brute-force search, i.e., for each prototype we produce a new early design by
assigning both $x_{cd}$ and $y_{cf}$ to a possible value in their range.
The runtime of \liftcreatebf{} grows with the shaft  size and it is up to 
three orders of magnitude greater than \liftcreatehr, the
largest slice of runtime consumed by the validation phase. This is
reasonable because even if the expansion phase generates a large
number of alternatives, no processing  is performed on them. This
means that \liftcreatebf{} wastes a lot of processing time just to discard
unfeasible configurations.

\paragraph{\liftcreatega.}
%
\begin{table}[t]
	\caption{\label{table:genProjResult10}Results obtained with \liftcreatega{}
		with mutation value $10$\% on the baseline encoding. ``\textbf{POP}''
		is the population size, 
		``\textbf{V}'' is the number of feasible projects, ``\textbf{C}'' is the
		number of clusters, ``\textbf{I=C $\cap$ H}'' is the number of clusters
		shared by \liftcreatega{} and \liftcreatehr.
		For each pair, column ``MED$_x$'' and ``IQR$_x$'' are the median and the
		interquartile range of value $x$, respectively. Column
		``$\frac{\text{MED}_I}{\text{MED}_C}$'' is the
		ratio between shared clusters and \liftcreatega{} ones.} 
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{l r rr rr rr r}
		\toprule
		\multirow{2}{*}{\bf Shaft size} 
		& \multirow{2}{*}{\bf POP} & \multicolumn{2}{c}{\bf V} & \multicolumn{2}{c}{\bf C} &
		\multicolumn{2}{c}{\bf I=C $\cap$ H} & 
		\multirow{2}{*}{$\frac{\text{\textbf{MED}}_I}{\text{\textbf{MED}}_C}$[\%]}\\
		\cmidrule{3-8}
		&& { $MED_V$} & {$IQR_V$} & {$MED_C$} & {$IQR_C$} & {$MED_I$}
		& {$IQR_I$} & \\
		\midrule
		1300 $\times$ 800 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & --\\
		1300 $\times$ 900 & 6392 & 5569.5 & 11.75 & 26.0 & 2.75 & 26.0 & 2.75 & 100.00\\
		1300 $\times$ 1000 & 13192 & 11098.0 & 7.5 & 17.0 & 0.0 & 16.0 & 0.0 & 94.12\\
		1300 $\times$ 1100 & 19992 & 16090.0 & 76.25 & 4.0 & 1.0 & 4.0 & 1.0 & 100.00\\
		1300 $\times$ 1200 & 26792 & 22122.5 & 15.75 & 30.0 & 1.0 & 30.0 & 1.0 & 100.00\\
		1300 $\times$ 1300 & 33592 & 26768.0 & 58.0 & 30.0 & 1.75 & 29.0 & 1.75 & 96.67\\
		1300 $\times$ 1400 & 40392 & 32153.5 & 726.75 & 123.0 & 18.75 & 123.0 & 18.75 & 100.00\\
		1300 $\times$ 1500 & 47192 & 37444.5 & 590.0 & 89.0 & 7.75 & 89.0 & 7.75 & 100.00\\
		1500 $\times$ 800 & 0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & --\\
		1500 $\times$ 900 & 8272 & 1363.0 & 149.5 & 16.0 & 5.0 & 12.5 & 4.75 & 78.13\\
		1500 $\times$ 1000 & 17072 & 7694.0 & 1811.75 & 48.0 & 4.75 & 47.0 & 5.5 & 97.92\\
		1500 $\times$ 1100 & 25872 & 21195.5 & 48.75 & 52.0 & 0.0 & 52.0 & 0.0 & 100.00\\
		1500 $\times$ 1200 & 34672 & 28658.0 & 58.0 & 66.0 & 1.75 & 59.0 & 1.75 & 89.39\\
		1500 $\times$ 1300 & 43472 & 35697.0 & 30.5 & 89.0 & 2.0 & 89.0 & 2.0 & 100.00\\
		1500 $\times$ 1400 & 52272 & 38497.5 & 1846.5 & 223.5 & 16.5 & 223.5 & 16.5 & 100.00\\
		1500 $\times$ 1500 & 61072 & 47797.5 & 710.25 & 107.0 & 6.0 & 107.0 & 6.0 & 100.00\\
		\bottomrule
	\end{tabular}
\end{table}
%
Table~\ref{table:genProjResult10} shows the results of
\liftcreatega{}. According to some preliminary experiments 
that we do not show for the sake of brevity, we set the mutation rate
to 10\%, i.e., individuals are affected by random gene mutation with a
probability of 10\%. In order to account for stochastic variability,
we consider 
for each setting $50$ sample runs of \liftcreatega{}, with a unique
seed for each sample. In our implementation, the GA stops when the
fitness of the fittest individuals remains unchanged for $10$ 
generations in a row. Column ``POP'' refers to the population size, 
which is one tenth of the total solution space --- overestimated as
the product between the cardinalities of the domains of car frames and
doors. Since we run different samples, we compute the median and
interquartile range 
for each reported value: ``V'' is the number of valid designs and 
``C'' is the number of what we defined in Section~\ref{sec:solutions}
clusters, i.e., designs sharing the same components.
We also report the cardinality (median and interquartile range) of the 
intersection between \liftcreatega{} clusters and \liftcreatehr{} and 
the ratio between the said intersection and the total number of clusters
(column $\frac{\text{MED}_I}{\text{MED}_C}$ in 
Table~\ref{table:genProjResult10}). We can observe that, while the median
of valid designs grows with the size of the shaft, their spread is
almost always at least two orders of magnitude smaller. Concerning 
clusters, the difference between valid designs and their clusterization
is also about two orders of magnitude, meaning that lots of feasible
configurations share the same car frame and doors. Finally, the overlap
of the clusters with the designs generated by \liftcreatehr{} is 
substantial, reaching $100\%$ on $9$ out of $14$ setups --- the two
setups in which no feasible design is found are not considered --- and
on the remaining setups it never drops below $78.13\%$. Overall, these
results show that \liftcreatega{} is able to reach the same ``quality''
as \liftcreatehr{}, provided a proper hyperparameter tuning.

In terms of sheer performances \liftcreatehr{} is still superior to 
\liftcreatega{}, but the runtimes of the latter are reasonable for online 
deployment with the added flexibility of a ``declarative'' encoding: 
adding a new constraint to \liftcreatega{} only amounts to add a term to 
the fitness function, whereas in the case of \liftcreatehr{} any change 
involves modifying the code.
%% One last remark about \liftcreatega{} concerns the performances of
%% genetic algorithms with mutation rates higher than $10$\%. As it can
%% be observed in the tables reported in the appendix, those
%% configurations are overall worse than the one with mutation rate
%% $10\%$. Lowering the mutation rate speeds up \liftcreatega{}, but 
%% also reduces drastically the similarity with respect to
%% \liftcreatehr{}: less mutation implies that fewer alternative projects
%% are explored, causing \liftcreatega{} to produce several ``clones'' of
%% the same individuals and failing to find alternative, yet satisfactory
%% solutions. 

\paragraph{\liftcreatecp{} and \liftcreatesmt.}
%
\begin{table}[t]
	\caption{\label{tab:baseline} Comparison of computation time for
		solvers on the baseline encoding: the first column reports the 
		setup and the other columns	report the time (ms) taken to solve 
		each setup by the solvers --- best times appear in boldface.} 
	\centering
	\resizebox{\columnwidth}{!}{%
	\begin{tabular}{l r r r r r r r}
		\toprule
		\multirow{2}{*}{\textbf{Shaft size}} & 
		\multicolumn{5}{c}{\textbf{MiniZinc}} & \multicolumn{2}{c}{\textbf{SMT-LIB}} \\
		\cmidrule{2-8}
		 & OR-Tools & Chuffed & ECL$^i$PS$^e$ &	CPLEX & Gurobi & z3 & OptiMathSat \\
		\midrule
		$1300 \times 800$  & 662 & 200 & 924  & 856  & 886  & \textbf{100} & 254 \\
		$1300 \times 900$  & 645 & \textbf{198} & 703  & 1020 & 1802 & 432 & 30680 \\
		$1300 \times 1000$ & 674 & \textbf{192} & 1401 & 918  & 933  & 416 & 58066 \\
		$1300 \times 1100$ & 659 & \textbf{179} & 1734 & 940  & 971  & 582 & 154739 \\
		$1300 \times 1200$ & 655 & \textbf{191} & 1796 & 1056 & 1237 & 417 & 82698 \\
		$1300 \times 1300$ & 661 & \textbf{188} & 1771 & 1090 & 1725 & 495 & 100822 \\
		$1300 \times 1400$ & 637 & \textbf{188} & 1366 & 918  & 887* & 435 & 79323 \\
		$1300 \times 1500$ & 672 & \textbf{206} & 875  & 1118 & 925* & 517 & 98355 \\
		$1500 \times 800$  & 644 & 199 & 678  & 1023 & 824  & \textbf{116} & 247 \\
		$1500 \times 900$  & 664 & \textbf{179} & 691  & 902  & 881  & 787 & 101458 \\
		$1500 \times 1000$ & 673 & \textbf{195} & 1379 & 987  & 887* & 619 & 70082 \\
		$1500 \times 1100$ & 639 & \textbf{206} & 1942 & 971  & 903  & 682 & 105071 \\
		$1500 \times 1200$ & 660 & \textbf{264} & 2024 & 1060 & 934  & 501 & 83719 \\
		$1500 \times 1300$ & 636 & \textbf{224} & 2412 & 987  & 1018 & 417 & 121801 \\
		$1500 \times 1400$ & 645 & \textbf{192} & 1509 & 871  & 919  & 470 & 97753 \\
		$1500 \times 1500$ & 653 & \textbf{216} & 845  & 856  & 935  & 463 & 142557 \\
		\bottomrule
	\end{tabular}}
\end{table}
%
We test our SMT-LIB encoding with two OMT solvers, namely z3~\cite{z3}
by Microsoft Research and OptiMathSat~\cite{sebastiani2018optimathsat}
by FBK, and our MiniZinc encoding with five different solvers. 
We use the lazy clause generation based solver 
Chuffed~\cite{chu2013improving}, the MiniZinc challenge winner Google
OR-Tools~\cite{ortools}, the CLP solver ECL$^i$PS$^e$~\cite{schimpf_shen_2012}
and the two MIP solvers CPLEX~\cite{cplex} and Gurobi~\cite{gurobi}.
With all these solvers we can observe how different approaches in solving
combinatorial optimization problems behave with our encoding 
choices. In more detail, we run Chuffed v0.10.3, OR-Tools v7.8, ECL$^i$PS$^e$ 
v7.0, CPLEX v12.7, Gurobi v9.0.1, z3 v4.8.7 and OptiMathSat v1.7.0.1.
We consider the default configuration of every solver, even 
if we are aware that tuning each solver for the specific problem might
yield better results. However, we do not wish to introduce bias in our
experiments due to the fact that we may know a solver or a technique
better than others and thus obtain effective configurations on
specific solvers only. Notice that z3 and OptiMathSat do not generate 
proofs of their results in their default configuration. Overall, the
baseline encoding features $29$ parameters and $10$ decision variables, 
whereas the full encoding features $42$ parameters and $17$ decision 
variables. The number of constraints varies from a minimum of $30$ for 
the baseline encoding considering arrays and functions to $401$ 
for the full encoding with implications to represent parameters and 
look-up tables. 

In Table~\ref{tab:baseline} we show the results obtained on the
baseline encoding by all the solvers we consider. For each solver we
report the best time obtained on two variations: one in which the
selection of components is based on arrays and another featuring
Boolean implications. Both variations are integer-based because not
all the solvers support arithmetic over reals, so we do not
consider relaxations here; also, since the car surface computation involves
a division, we omit the deduction of the car
payload and passengers which are required for a complete
design. All the solvers leveraging MiniZinc 
encodings  fare the best runtime when the component parameters are
encoded with arrays: CP solvers like Chuffed seem to make effective
use of element constraints and MIP solvers appear to handle the
translation of array constraints better than Boolean implications. On
the other hand, OMT solvers run faster on the version based
on Boolean implications, as the addition of arrays involves dealing
with more theories at once and this inevitably hurts performances.

As we can observe in Table~\ref{tab:baseline}, Chuffed is
the one yielding the best runtimes, except for two
setups where z3 is the fastest solver. Noticeably, these setups do 
not admit a feasible configuration given the shaft size and the
components available. z3 and OR-Tools are second best, their runtimes
being always less than one second; MIP solvers CPLEX and Gurobi seem
slightly less effective than the leading pack. In some cases, marked 
with an asterisk in Table~\ref{tab:baseline}, Gurobi returned 
``\textit{UNSAT or UNKNOWN}'' as an answer even if a solution exists
and the MiniZinc file is the same for all solvers, so we conjecture 
that numerical stability might be an issue in these cases, but we are 
investigating other potential causes. ECL$^i$PS$^e$ results are mixed, 
i.e., some setups are solved faster than OR-Tools or z3, others take
more than two seconds to solve. OptiMathSat is surprisingly slow on 
these encodings: if we exclude scenarios for which no feasible 
configuration exists, then OptiMathSat best result is 30 seconds to 
solve the $1300 \times 900$ setup.

\begin{table}[t!]
	\caption{\label{tab:omt-full} Comparison of computation time for 
		z3 and OptiMathSat on the full encoding: the first column reports
		each setup; the other columns, grouped by solver, report runtimes 
		(ms) of different versions: integer-based ``\textbf{I}'', relaxed  
		``\textbf{I + R}'' and relaxed with functions ``\textbf{I + R + F}'',
		respectively. Subcolumns ``\textbf{SO}'' and ``\textbf{MO}'' refer 
		to single objective and multiobjective optimization, respectively
		--- best  times among z3 and OptiMathSat appear in boldface. The
		last column reports \liftcreate{} heuristic engine runtimes.}
	\centering
	\resizebox{\columnwidth}{!}{%
	\begin{tabular}{l r r r r r r r r r r r r r}
		\toprule
		%\cline{2-13}
		 & 
		\multicolumn{6}{c}{\textbf{z3}} &
		\multicolumn{6}{c}{\textbf{OptiMathSat}} & \\
		\cmidrule{2-13}
		
		\textbf{Shaft size} &
		\multicolumn{2}{c}{\textbf{I}} &
		\multicolumn{2}{c}{\textbf{I + R}} &
		\multicolumn{2}{c}{\textbf{I + R + F}} & 
		\multicolumn{2}{c}{\textbf{I}} &
		\multicolumn{2}{c}{\textbf{I + R}} &
		\multicolumn{2}{c}{\textbf{I + R + F}} & 
		\textbf{Heuristic} \\
		%\cline{2-13}
		& \textbf{SO} & \textbf{MO} 
		& \textbf{SO} & \textbf{MO}
		& \textbf{SO} & \textbf{MO} 
		& \textbf{SO} & \textbf{MO} 
		& \textbf{SO} & \textbf{MO}
		& \textbf{SO} & \textbf{MO} & \\
		\midrule
		
		$1300 \times 800$ & 157 & 149 & 131 & 134 & 143 & 221
		& 109 & 119 & \textbf{100} & 131 & 116 & 110 & 583 \\
		$1300 \times 900$ & 8878 & 229522 & 1205 & \textbf{844} & 1978 & 2321
		& --- & --- & 74960 & 53535 & 68215 & 52068 & 1784 \\
		$1300 \times 1000$ & 36120 & 133325 & 2818 & 3362 & 4433 & \textbf{2704}
		& 156761 & 48328 & 136109 & 107356 & 132166 & 112379 & 921 \\
		$1300 \times 1100$ & 36448 & 60589 & 3514 & 1967 & 2365 & \textbf{1554}
		& 192198 & 127753 & 160883 & 176491 & 199352 & 113889 & 2177 \\
		$1300 \times 1200$ & 42328 & 5530 & 6876 & 3460 & \textbf{2637} & 4155
		& --- & 208852 & 276380 & 181817 & 193987 & 160401 & 6865 \\
		$1300 \times 1300$ & 94325 & 8982 & 22279 & \textbf{2521} & 5294 & 5304
		& 244973 & 129848 & 225067 & 165818 & 292777 & 197777 & 15278 \\	
		$1300 \times 1400$ & 30452 & 133087 & 7374 & \textbf{1779} & 11096 & 3707
		& 259953 & 244078 & --- & 256791 & --- & 242488 & 11190 \\
		$1300 \times 1500$ & 177355 & 25697 & 18810 & 4061 & 234235 & \textbf{1998}
		& 258119 & 213104 & 259693 & 172842 & 274986 & 222485 & 24380 \\
		$1500 \times 800$ & 176 & 141 & 121 & 114 & 140 & 129
		& 100 & \textbf{85} & 100 & \textbf{85} & 100 & 101 & 926 \\ 
		$1500 \times 900$ & 25964 & 56674 & 1619 & \textbf{1212} & 3382 & 1876
		& 141359 & --- & 206751 & 95370 & 167671 & 100623 & 5215 \\ 
		$1500 \times 1000$ & 91242 & 235192 & 2888 & 1803 & 5121 & \textbf{1725}
		& --- & 118777 & 223241 & 93759 & 173623 & 187153 & 2952 \\
		$1500 \times 1100$ & --- & 18023 & 4977 & 7517 & \textbf{3925} & 4446
		& 219596 & 187570 & 205041 & 179414 & 183862 & 156035 & 4875 \\
		$1500 \times 1200$ & 139993 & 68562 & 7001 & \textbf{1242} & 7431 & 1571
		& 251651 & 148664 & 231829 & 70431 & 254111 & 189705 & 6232 \\
		$1500 \times 1300$ & 291712 & --- & 26724 & 4895 & 20263 & \textbf{4325}
		& --- & 225509 & --- & 232735 & --- & 255728 & 33785 \\
		$1500 \times 1400$ & --- & 6264 & 35073 & 3139 & 169215 & \textbf{2675}
		& --- & 184555 & 271054 & 107886 & --- & 180857 & 21910 \\
		$1500 \times 1500$ & --- & 17824 & 37722 & 2703 & 121472 & \textbf{2528}
		& 257242 & 222360 & --- & 167762 & --- & 251033 & 8699 \\
		\bottomrule
	\end{tabular}}
\end{table}
%
When considering the full encoding, we limit our comparison to 
z3 and OptiMathSat, since they are the only ones that appear to handle
encodings which contain a substantial part of arithmetic over reals
involved in cylinder selection, sizing and computation of forces on
the car rails. Among the MiniZinc-based  
tools, ECL$^i$PS$^e$ is meant to support arithmetic over reals, but
even the baseline encoding with relaxations resulted in a
timeout for every setup other than the ones for which no feasible
configuration exists. We experimented also with OR-Tools on
an encoding obtained considering fixed-point arithmetic over 64 bit
integers, but to no avail. We did not try the fixed-point encoding on
other CP tools as they do not support 64 bit precision which
is the least one required to avoid overflowing the calculations.
In Table~\ref{tab:omt-full} we collect the   
results of the comparison between z3 and OptiMathSat, adding
the runtime of the heuristic search performed by \liftcreate{} for
reference. We focus on the implication-based encoding given the 
results with the baseline encoding. In the table, columns
labeled ``\textbf{I}'' report runtimes on the integer-based versions,
columns labeled ``\textbf{I+R}'' report runtimes on relaxed versions,
and columns  labeled ``\textbf{I+R+F}'' report runtimes on
versions where look-up tables are represented as
nested \emph{if-then-else} functions rather than straight 
implications. The  columns ``\textbf{SO}'' and ``\textbf{MO}'' report
the results of single-objective and multi-objective optimization,
respectively. The choice of the weights detailed in the setup reflects 
that the first three components of the cost function have the same priorities.
Different weights could be chosen according to the user's preferences, 
and we know --- from other experiments that we do not show here to save 
space --- that different choices do not impact on performances.  

Considering the results in Table~\ref{tab:omt-full}, we see that
the integer-based version of the full encoding is the least appealing
option: while z3 performs slightly better than OptiMathSat on this
version, other solutions yield faster runtimes. In particular,
relaxing the encoding has a substantial impact both on z3 and
OptiMathSat: solving time decreases by orders of magnitude in some
cases with  respect to the integer-based encoding. Finally,
considering the addition of native SMT-LIB functions we see that the
results are mixed, i.e., it is not so clear that choosing them
improves the solving time. Noticeably, while OptiMathSat remains
slower than z3, it never exceeds the time limit on this encoding.
As for single vs. multi-objective encoding, we can see that the
multi-objective approach performs better than the single-objective
one. In spite of some exceptions, multi-objective optimization ---
specifically, with z3, relaxed encodings and native SMT-LIB functions
--- seems to be the winning option overall.
When it comes to comparing the heuristic engine of \liftcreate{} with
the best results of the constraint-based approach, we should take into
account that the former deals with the \emph{complete} design cycle
and not just with some subtasks. Given this initial bias, that in
some cases the heuristic engine outperforms most constraint-based
solutions, but it is overall slower than the best ones, it is fair to
say that OMT solvers with relaxed encodings and multi-objective
optimization provide a feasible replacement to heuristic search in
the design subtasks that we considered here.



